{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium as g\n",
    "from folium.plugins import MarkerCluster\n",
    "from haversine import haversine\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./jeju_data/train.parquet')\n",
    "test = pd.read_parquet('./jeju_data/test.parquet')\n",
    "weather = pd.read_csv('./jeju_data/jeju_weather.csv', encoding='cp949')\n",
    "weather = weather[weather['지점명']=='제주']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_year(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.year\n",
    "    return md\n",
    "\n",
    "\n",
    "def make_month(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.month\n",
    "    return md\n",
    "\n",
    "\n",
    "def make_day(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.day\n",
    "    return md\n",
    "\n",
    "\n",
    "def turn_road_rate(df):\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 107), 'turn_road_rate'] = 0\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 103), 'turn_road_rate'] = 1\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 107), 'turn_road_rate'] = 2\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 106), 'turn_road_rate'] = 3\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 103), 'turn_road_rate'] = 4\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 106), 'turn_road_rate'] = 5\n",
    "    return df['turn_road_rate']\n",
    "\n",
    "\n",
    "def end_turn_road_rate(df):\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 107), 'end_turn_road_rate'] = 0\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 103), 'end_turn_road_rate'] = 1\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 107), 'end_turn_road_rate'] = 2\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 106), 'end_turn_road_rate'] = 3\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 103), 'end_turn_road_rate'] = 4\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 106), 'end_turn_road_rate'] = 5\n",
    "    return df['end_turn_road_rate']\n",
    "\n",
    "\n",
    "def make_dist(df):\n",
    "    dist = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        start_location = (df['start_latitude'][i], df['start_longitude'][i])\n",
    "        end_location = (df['end_latitude'][i], df['end_longitude'][i])\n",
    "        \n",
    "        dist.append(haversine(start_location, end_location))\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def make_week(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    data = pd.to_datetime(dt)\n",
    "\n",
    "    b_list = []\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        b_list.append(data[i].weekday())\n",
    "    \n",
    "    return b_list\n",
    "\n",
    "\n",
    "def week_mapping(df):\n",
    "    if df['week'] <= 4:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "\n",
    "# cyclical continuous features - 24-hour time 주기성을 가지는 데이터를 알맞게 변환\n",
    "def cyclical_feature(df):\n",
    "    df['sin_time'] = np.sin(2*np.pi*df.base_hour/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df.base_hour/24)\n",
    "    \n",
    "    \n",
    "def over_max_speed(df):\n",
    "    df.loc[(df['maximum_speed_limit'] == 30), 'over_max_speed'] = 1\n",
    "    df.loc[(df['maximum_speed_limit'] == 40), 'over_max_speed'] = 1\n",
    "    df.loc[(df['maximum_speed_limit'] == 50), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 60), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 70), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 80), 'over_max_speed'] = 0\n",
    "    \n",
    "    return df['over_max_speed']\n",
    "\n",
    "\n",
    "def make_Ymd(df):\n",
    "    dt = df['일시'].astype('str')\n",
    "    month_data = pd.to_datetime(dt).dt.strftime(\"%Y%m%d\")\n",
    "    return month_data\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "def geocoding_reverse(lat_lng_str): \n",
    "    geolocoder = Nominatim(user_agent = 'South Korea', timeout=None)\n",
    "    address = geolocoder.reverse(lat_lng_str)\n",
    "\n",
    "    return address\n",
    "\n",
    "# train['location'] = train['start_latitude'].astype(str) + ',' + train['start_longitude'].astype(str)\n",
    "# geocoding_reverse(train['location'][10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4701217/4701217 [01:49<00:00, 42939.86it/s]\n",
      "100%|██████████| 4701217/4701217 [00:39<00:00, 118103.76it/s]\n",
      "100%|██████████| 291241/291241 [00:06<00:00, 42892.52it/s]\n",
      "100%|██████████| 291241/291241 [00:02<00:00, 122640.70it/s]\n"
     ]
    }
   ],
   "source": [
    "tra = make_dist(train)\n",
    "train['year'] = make_year(train)\n",
    "train['month'] = make_month(train)\n",
    "train['day'] = make_day(train)\n",
    "train['turn_road_rate'] = turn_road_rate(train)\n",
    "train['end_turn_road_rate'] = end_turn_road_rate(train)\n",
    "train['distance'] = tra\n",
    "train['week'] = make_week(train)\n",
    "train['week'] = train.apply(week_mapping, axis=1)\n",
    "train['over_max_speed'] = over_max_speed(train)\n",
    "# cyclical_feature(train)\n",
    "\n",
    "tes = make_dist(test)\n",
    "test['year'] = make_year(test)\n",
    "test['month'] = make_month(test)\n",
    "test['day'] = make_day(test)\n",
    "test['turn_road_rate'] = turn_road_rate(test)\n",
    "test['end_turn_road_rate'] = end_turn_road_rate(test)\n",
    "test['distance'] = tes\n",
    "test['week'] = make_week(test)\n",
    "test['week'] = test.apply(week_mapping, axis=1)\n",
    "test['over_max_speed'] = over_max_speed(test)\n",
    "\n",
    "# cyclical_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['일시'] = make_Ymd(weather)\n",
    "weather = weather.drop(['지점', '지점명'], axis=1)\n",
    "weather = weather.rename(columns={'일시': 'base_date'})\n",
    "train['base_date'] = train['base_date'].astype('str')\n",
    "merge = pd.merge(train, weather, on='base_date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def road_division(df):    \n",
    "#     df.loc[(df['road_name']).str.contains('지방도'), 'road_division'] = 0\n",
    "#     df.loc[(df['road_name']).str.contains('일반국도'), 'road_division'] = 1\n",
    "#     df.loc[((df['road_name']).str.contains('지방도', na=False)) & ((train['road_name']).str.contains('일반국도', na=False)), 'road_division'] = 2\n",
    "\n",
    "# train['road_division'] = road_division(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['일강수량(mm)'] = merge['일강수량(mm)'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def road_division():\n",
    "#     if train[train['road_name'].str.contains('지방도')]: return 0\n",
    "#     elif train[train['road_name'].str.contains('일반국도')]: return 1\n",
    "#     else: return 2\n",
    "\n",
    "# train['road_division'] = train['road_division'].apply(road_division())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexl = train[train['road_name'] == '-'].index\n",
    "train.drop(indexl, inplace=True)\n",
    "\n",
    "tindexl = test[test['road_name'] == '-'].index\n",
    "test.drop(tindexl, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_col = ['day_of_week', 'start_turn_restricted', 'end_turn_restricted', 'road_name', 'start_node_name', 'end_node_name']\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train[i])\n",
    "    train[i] = le.transform(train[i])\n",
    "\n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i] = le.transform(test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\n",
    "    ['id', 'base_date', 'target'], axis=1)\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "test = test.drop(\n",
    "    ['id', 'base_date'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_best_parm = {'learning_rate': 0.21020261303127669, 'bagging_temperature': 75.5373108410501, 'n_estimators': 4891, 'max_depth': 12, 'random_strength': 19, 'colsample_bylevel': 0.45647247075797176, 'l2_leaf_reg': 4.82164247062514e-07, 'min_child_samples': 82, 'max_bin': 448, 'od_type': 'IncToDec'}\n",
    "# xgb_best_param = {'n_estimators': 2626, 'max_depth': 15, 'min_child_weight': 39, 'gamma': 1, 'colsample_bytree': 0.8320047615067258, 'lambda': 8.576465850923702, 'alpha': 1.2726833950057483, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# LR = CatBoostRegressor(iterations=1000).fit(x_train, y_train)\n",
    "# y_pred = LR.predict(x_val)\n",
    "# mae = mean_absolute_error(y_val, y_pred)\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kki96\\miniconda3\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.767482240889293\n"
     ]
    }
   ],
   "source": [
    "LR = XGBRegressor().fit(x_train, y_train)\n",
    "y_pred = LR.predict(x_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = XGBRegressor(**xgb_best_param).fit(X, y)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submission['target'] = y_pred\n",
    "sample_submission.to_csv(\"./submit_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from optuna import Trial\n",
    "# from optuna.samplers import TPESampler\n",
    "\n",
    "# # 1. Define an objective function to be maximized.\n",
    "# def objective_xgb(trial: Trial, x, y):\n",
    "\n",
    "\n",
    "# # 2. Suggest values for the hyperparameters using a trial object\n",
    "#     param = {\n",
    "#         \"n_estimators\": trial.suggest_int('n_estimators', 500, 4000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 8, 16),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "#         'gamma': trial.suggest_int('gamma', 1, 3),\n",
    "#         'learning_rate': 0.01,\n",
    "#         'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "#         'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "\n",
    "#     x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "#     model = XGBRegressor(**param)\n",
    "#     xgb_model = model.fit(x_train, y_train, verbose=False, eval_set=[(x_val, y_val)])\n",
    "#     y_pred = xgb_model.predict(x_val)\n",
    "#     score = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "# study.optimize(lambda trial: objective_xgb(trial, X, y), n_trials=30)\n",
    "# print('Best trial: score {},\\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
