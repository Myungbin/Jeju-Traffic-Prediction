{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날씨데이터 추가후 강수량 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium as g\n",
    "from folium.plugins import MarkerCluster\n",
    "from haversine import haversine\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('./jeju_data/train.parquet')\n",
    "test = pd.read_parquet('./jeju_data/test.parquet')\n",
    "weather = pd.read_csv('./jeju_data/jeju_weather.csv', encoding='cp949')\n",
    "weather = weather[weather['지점명']=='제주']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature만드는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_year(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.year\n",
    "    return md\n",
    "\n",
    "\n",
    "def make_month(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.month\n",
    "    return md\n",
    "\n",
    "\n",
    "def make_day(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    month_data = pd.to_datetime(dt)\n",
    "    md = month_data.dt.day\n",
    "    return md\n",
    "\n",
    "\n",
    "def turn_road_rate(df):\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 107), 'turn_road_rate'] = 0\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 103), 'turn_road_rate'] = 1\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 107), 'turn_road_rate'] = 2\n",
    "    df.loc[(df['start_turn_restricted'] == '있음') & (df['road_rating'] == 106), 'turn_road_rate'] = 3\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 103), 'turn_road_rate'] = 4\n",
    "    df.loc[(df['start_turn_restricted'] == '없음') & (df['road_rating'] == 106), 'turn_road_rate'] = 5\n",
    "    return df['turn_road_rate']\n",
    "\n",
    "\n",
    "def end_turn_road_rate(df):\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 107), 'end_turn_road_rate'] = 0\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 103), 'end_turn_road_rate'] = 1\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 107), 'end_turn_road_rate'] = 2\n",
    "    df.loc[(df['end_turn_restricted'] == '있음') & (df['road_rating'] == 106), 'end_turn_road_rate'] = 3\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 103), 'end_turn_road_rate'] = 4\n",
    "    df.loc[(df['end_turn_restricted'] == '없음') & (df['road_rating'] == 106), 'end_turn_road_rate'] = 5\n",
    "    return df['end_turn_road_rate']\n",
    "\n",
    "\n",
    "def make_dist(df):\n",
    "    dist = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        start_location = (df['start_latitude'][i], df['start_longitude'][i])\n",
    "        end_location = (df['end_latitude'][i], df['end_longitude'][i])\n",
    "        \n",
    "        dist.append(haversine(start_location, end_location))\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def make_week(df):\n",
    "    dt = df['base_date'].astype('str')\n",
    "    data = pd.to_datetime(dt)\n",
    "\n",
    "    b_list = []\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        b_list.append(data[i].weekday())\n",
    "    \n",
    "    return b_list\n",
    "\n",
    "\n",
    "def week_mapping(df):\n",
    "    if df['week'] <= 4:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "\n",
    "# cyclical continuous features - 24-hour time 주기성을 가지는 데이터를 알맞게 변환\n",
    "def cyclical_feature(df):\n",
    "    df['sin_time'] = np.sin(2*np.pi*df.base_hour/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df.base_hour/24)\n",
    "    \n",
    "    \n",
    "def over_max_speed(df):\n",
    "    df.loc[(df['maximum_speed_limit'] == 30), 'over_max_speed'] = 1\n",
    "    df.loc[(df['maximum_speed_limit'] == 40), 'over_max_speed'] = 1\n",
    "    df.loc[(df['maximum_speed_limit'] == 50), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 60), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 70), 'over_max_speed'] = 0\n",
    "    df.loc[(df['maximum_speed_limit'] == 80), 'over_max_speed'] = 0\n",
    "    \n",
    "    return df['over_max_speed']\n",
    "\n",
    "\n",
    "def make_Ymd(df):\n",
    "    dt = df['일시'].astype('str')\n",
    "    month_data = pd.to_datetime(dt).dt.strftime(\"%Y%m%d\")\n",
    "    return month_data\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "def geocoding_reverse(lat_lng_str): \n",
    "    geolocoder = Nominatim(user_agent = 'South Korea', timeout=None)\n",
    "    address = geolocoder.reverse(lat_lng_str)\n",
    "\n",
    "    return address\n",
    "\n",
    "# train['location'] = train['start_latitude'].astype(str) + ',' + train['start_longitude'].astype(str)\n",
    "# geocoding_reverse(train['location'][10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4701217/4701217 [01:03<00:00, 73540.61it/s]\n",
      "100%|██████████| 4701217/4701217 [00:28<00:00, 164037.90it/s]\n",
      "100%|██████████| 291241/291241 [00:03<00:00, 73222.59it/s]\n",
      "100%|██████████| 291241/291241 [00:01<00:00, 174291.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dist = make_dist(train)\n",
    "train['year'] = make_year(train)\n",
    "train['month'] = make_month(train)\n",
    "train['day'] = make_day(train)\n",
    "train['turn_road_rate'] = turn_road_rate(train)\n",
    "train['end_turn_road_rate'] = end_turn_road_rate(train)\n",
    "train['distance'] = train_dist\n",
    "train['week'] = make_week(train)\n",
    "train['week'] = train.apply(week_mapping, axis=1)\n",
    "train['over_max_speed'] = over_max_speed(train)\n",
    "# train['base_date'] = train['base_date'].astype('str')\n",
    "# train = pd.merge(train, weather, on='base_date', how='left')\n",
    "# train['일강수량(mm)'] = train['일강수량(mm)'].fillna(0)\n",
    "# cyclical_feature(train)\n",
    "\n",
    "test_dist = make_dist(test)\n",
    "test['year'] = make_year(test)\n",
    "test['month'] = make_month(test)\n",
    "test['day'] = make_day(test)\n",
    "test['turn_road_rate'] = turn_road_rate(test)\n",
    "test['end_turn_road_rate'] = end_turn_road_rate(test)\n",
    "test['distance'] = test_dist\n",
    "test['week'] = make_week(test)\n",
    "test['week'] = test.apply(week_mapping, axis=1)\n",
    "test['over_max_speed'] = over_max_speed(test)\n",
    "# test['base_date'] = test['base_date'].astype('str')\n",
    "# test = pd.merge(test, weather, on='base_date', how='left')\n",
    "# test['일강수량(mm)'] = test['일강수량(mm)'].fillna(0)\n",
    "# cyclical_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['일시'] = make_Ymd(weather)\n",
    "weather = weather.drop(['지점', '지점명'], axis=1)\n",
    "weather = weather.rename(columns={'일시': 'base_date'})\n",
    "train['base_date'] = train['base_date'].astype('str')\n",
    "\n",
    "test['base_date'] = test['base_date'].astype('str')\n",
    "merge = pd.merge(train, weather, on='base_date', how='left')\n",
    "merge1 = pd.merge(test, weather, on='base_date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['일강수량(mm)'] = merge['일강수량(mm)'].fillna(0)\n",
    "merge1['일강수량(mm)'] = merge1['일강수량(mm)'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge\n",
    "test = merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def road_division():\n",
    "#     if train[train['road_name'].str.contains('지방도')]: return 0\n",
    "#     elif train[train['road_name'].str.contains('일반국도')]: return 1\n",
    "#     else: return 2\n",
    "\n",
    "# train['road_division'] = train['road_division'].apply(road_division())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = train.copy()\n",
    "Test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_col = ['day_of_week', 'start_turn_restricted', 'end_turn_restricted']\n",
    "for i in str_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train[i])\n",
    "    train[i] = le.transform(train[i])\n",
    "\n",
    "    for label in np.unique(test[i]):\n",
    "        if label not in le.classes_:\n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test[i] = le.transform(test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\n",
    "    ['id', 'base_date', 'target', 'road_name', 'start_node_name', 'end_node_name'], axis=1)\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "test = test.drop(\n",
    "    ['id', 'base_date', 'road_name', 'start_node_name', 'end_node_name'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from optuna import Trial\n",
    "# from optuna.samplers import TPESampler\n",
    "\n",
    "# # 1. Define an objective function to be maximized.\n",
    "# def objective_xgb(trial: Trial, x, y):\n",
    "\n",
    "\n",
    "# # 2. Suggest values for the hyperparameters using a trial object\n",
    "#     param = {\n",
    "#         \"n_estimators\": trial.suggest_int('n_estimators', 500, 4000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 8, 16),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "#         'gamma': trial.suggest_int('gamma', 1, 3),\n",
    "#         'learning_rate': 0.01,\n",
    "#         'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "#         'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "\n",
    "#     x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "#     model = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0)\n",
    "#     xgb_model = model.fit(x_train, y_train, verbose=False, eval_set=[(x_val, y_val)])\n",
    "#     y_pred = xgb_model.predict(x_val)\n",
    "#     score = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "# study.optimize(lambda trial: objective_xgb(trial, X, y), n_trials=30)\n",
    "# print('Best trial: score {},\\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': 3932, 'max_depth': 16, 'min_child_weight': 81, 'gamma': 1, 'lambda': 0.00561769192036322, 'alpha': 0.09755201822188254, 'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = XGBRegressor(**param, tree_method='gpu_hist', gpu_id=0).fit(X, y)\n",
    "y_pred = LR.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./jeju_data/sample_submission.csv')\n",
    "sample_submission['target'] = y_pred\n",
    "sample_submission.to_csv(\"./submit_xgb_plz.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이항분포의 확률질량함수 0.3683860829875549\n",
      "이항분포의 확률질량함수 0.3683860829875546\n",
      "이항분포의 기대값 1.1898739999999999\n",
      "이항분포의 누적확률질량함수 0.6648303554045987\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "fac = np.math.factorial\n",
    "\n",
    "4.24955\n",
    "3.48311\n",
    "n1 = 28\n",
    "x1 = 1\n",
    "p1 = 0.0424955\n",
    "E1 = n1*p1\n",
    "V1 = n1*p1*(1-p1)\n",
    "pmf = fac(n1)/fac(x1)/fac(n1-x1) * p1**x1 * (1-p1)**(n1-x1)\n",
    "print('이항분포의 확률질량함수', binom.pmf(x1, n1, p1))\n",
    "print('이항분포의 확률질량함수', pmf)\n",
    "print('이항분포의 기대값', E1)\n",
    "\n",
    "print('이항분포의 누적확률질량함수', binom.cdf(x1, n1, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이항분포의 확률질량함수 0.36256499598688563\n",
      "이항분포의 확률질량함수 0.36256499598688574\n",
      "이항분포의 기대값 1.2539196\n",
      "이항분포의 누적확률질량함수 0.6416390756608674\n"
     ]
    }
   ],
   "source": [
    "n1 = 36\n",
    "x1 = 1\n",
    "p1 = 0.0348311\n",
    "E1 = n1*p1\n",
    "V1 = n1*p1*(1-p1)\n",
    "pmf = fac(n1)/fac(x1)/fac(n1-x1) * p1**x1 * (1-p1)**(n1-x1)\n",
    "print('이항분포의 확률질량함수', binom.pmf(x1, n1, p1))\n",
    "print('이항분포의 확률질량함수', pmf)\n",
    "print('이항분포의 기대값', E1)\n",
    "\n",
    "print('이항분포의 누적확률질량함수', binom.cdf(x1, n1, p1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
